-----------CREATING DATASETS-------------
> CREATING TRAINING AND VALIDATION SETS
> LOADING SIMPSONSVQA QUESTION DICTIONARY
/home/ndhuynh/.conda/envs/cartoon/lib/python3.9/site-packages/torchvision/transforms/transforms.py:891: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
/home/ndhuynh/.conda/envs/cartoon/lib/python3.9/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
> LOADING SIMPSONSVQA ANNOTATION DICTIONARY
> LOADING SIMPSONSVQA QUESTION DICTIONARY
> LOADING SIMPSONSVQA ANNOTATION DICTIONARY
/home/ndhuynh/.conda/envs/cartoon/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/home/ndhuynh/.conda/envs/cartoon/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Data Size:
  Train: 32
  Validation:32
CREATING HieVQA
/home/ndhuynh/.conda/envs/cartoon/lib/python3.9/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
### lr_mult,  2
### num_training_steps,  100
### num_warmup_steps,  1
DistributedDataParallel(
  (module): VQAHieVQA(
    (image_encoder): ImageEncoder(
      (extractor): VGG(
        (features): Sequential(
          (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): ReLU(inplace=True)
          (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (6): ReLU(inplace=True)
          (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (8): ReLU(inplace=True)
          (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (11): ReLU(inplace=True)
          (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (13): ReLU(inplace=True)
          (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (15): ReLU(inplace=True)
          (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (18): ReLU(inplace=True)
          (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (20): ReLU(inplace=True)
          (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (22): ReLU(inplace=True)
          (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (25): ReLU(inplace=True)
          (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (27): ReLU(inplace=True)
          (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (29): ReLU(inplace=True)
          (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        )
        (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
        (classifier): Sequential(
          (0): Linear(in_features=25088, out_features=4096, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.5, inplace=False)
          (3): Linear(in_features=4096, out_features=4096, bias=True)
          (4): ReLU(inplace=True)
          (5): Dropout(p=0.5, inplace=False)
        )
      )
      (fflayer): Sequential(
        (0): Linear(in_features=4096, out_features=1024, bias=True)
        (1): Tanh()
      )
    )
    (word_embeddings): Embedding(7057, 300)
    (question_encoder): QuestionEmbedding(
      (gru): GRU(300, 512, batch_first=True)
      (fc): Linear(in_features=512, out_features=1024, bias=True)
    )
    (vqa_mlp): VQA_header(
      (vqa_headers): ModuleDict(
        (yes/no): Sequential(
          (0): Linear(in_features=1024, out_features=1000, bias=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Tanh()
          (3): Linear(in_features=1000, out_features=3, bias=True)
        )
        (color): Sequential(
          (0): Linear(in_features=1024, out_features=1000, bias=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Tanh()
          (3): Linear(in_features=1000, out_features=21, bias=True)
        )
        (number): Sequential(
          (0): Linear(in_features=1024, out_features=1000, bias=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Tanh()
          (3): Linear(in_features=1000, out_features=9, bias=True)
        )
        (action): Sequential(
          (0): Linear(in_features=1024, out_features=1000, bias=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Tanh()
          (3): Linear(in_features=1000, out_features=17, bias=True)
        )
        (object): Sequential(
          (0): Linear(in_features=1024, out_features=1000, bias=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Tanh()
          (3): Linear(in_features=1000, out_features=153, bias=True)
        )
        (human): Sequential(
          (0): Linear(in_features=1024, out_features=1000, bias=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Tanh()
          (3): Linear(in_features=1000, out_features=13, bias=True)
        )
        (other): Sequential(
          (0): Linear(in_features=1024, out_features=1000, bias=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Tanh()
          (3): Linear(in_features=1000, out_features=47, bias=True)
        )
        (location): Sequential(
          (0): Linear(in_features=1024, out_features=1000, bias=True)
          (1): Dropout(p=0.5, inplace=False)
          (2): Tanh()
          (3): Linear(in_features=1000, out_features=10, bias=True)
        )
      )
      (vqa_loss_func): CrossEntropyLoss()
    )
    (questiont_type_mlp): QuestionType(
      (qt_header): Sequential(
        (0): Linear(in_features=1024, out_features=1000, bias=True)
        (1): Dropout(p=0.5, inplace=False)
        (2): Tanh()
        (3): Linear(in_features=1000, out_features=8, bias=True)
      )
      (qt_loss_fn): CrossEntropyLoss()
    )
    (qt_loss_func): CrossEntropyLoss()
  )
)
---------------------------------------------------------------------------------------------------- Epoch 0 ----------------------------------------------------------------------------------------------------
)
)
)
)
)
)
)
)
)
)
)
)
)
)
)
)
)
)
)
)
Exception ignored in: <function _releaseLock at 0x7f534c2248b0>
Traceback (most recent call last):
  File "/home/ndhuynh/.conda/envs/cartoon/lib/python3.9/logging/__init__.py", line 227, in _releaseLock
    def _releaseLock():
KeyboardInterrupt:
